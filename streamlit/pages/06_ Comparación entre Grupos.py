import json
from pathlib import Path
import altair as alt
import numpy as np
import pandas as pd
import tifffile
from scipy import stats
import pingouin as pg
import streamlit as st
from ui.sidebar import render_sidebar
from ui.plots import GROUP_SCALE, PALETTE, boxplot_with_ticks, apply_theme

# Ra√≠z del repo
ROOT = Path(__file__).resolve().parents[2]
RAW_DIR = ROOT / "data" / "raw"
PROC_DIR = ROOT / "data" / "processed"

st.title("Comparaci√≥n entre Grupos (CTL vs Hipoxia)")
render_sidebar(show_calibration=True)
apply_theme(st)

# --- Funciones Estad√≠sticas (Sin cambios) ---
def run_comparison_test(a: np.ndarray, b: np.ndarray, alpha: float = 0.05) -> dict:
    """
    Realiza una comparaci√≥n estad√≠stica robusta entre dos grupos (a y b).
    Comprueba Normalidad (Shapiro) -> Elige Welch (normal) o Mann-Whitney (no normal).
    """
    results = {
        'test_name': None, 'comparison_target': None, 'stat_label': None, 
        'stat': np.nan, 'p_value': np.nan, 'is_a_normal': False, 
        'is_b_normal': False, 'message': None, 'n_a': a.size, 'n_b': b.size
    }
    # Manejar casos borde
    if a.size < 3 or b.size < 3:
        results['message'] = f"No hay suficientes datos (CTL n={a.size}, Hipoxia n={b.size}) para un test robusto."
        return results
    a_var, b_var = np.var(a, ddof=1), np.var(b, ddof=1)

    # Test de Normalidad
    if a_var > 1e-10:
        try:
            _, shapiro_a_p = stats.shapiro(a); results['is_a_normal'] = shapiro_a_p > alpha
        except stats.common.ShapiroError: results['is_a_normal'] = False
    if b_var > 1e-10:
        try:
            _, shapiro_b_p = stats.shapiro(b); results['is_b_normal'] = shapiro_b_p > alpha
        except stats.common.ShapiroError: results['is_b_normal'] = False
    
    # Elegir Test
    if results['is_a_normal'] and results['is_b_normal']:
        # Param√©trico: Welch's t-test
        results.update({'test_name': "Test t de Welch", 'comparison_target': "medias", 'stat_label': 't'})
        stat, p_value = stats.ttest_ind(a, b, equal_var=False, nan_policy='omit')
    else:
        # No Param√©trico: Mann-Whitney U
        results.update({'test_name': "U de Mann-Whitney", 'comparison_target': "medianas", 'stat_label': 'U'})
        try:
            if a_var < 1e-10 and b_var < 1e-10 and np.mean(a) == np.mean(b):
                 stat, p_value = np.nan, 1.0; results['message'] = "Datos id√©nticos."
            else:
                stat, p_value = stats.mannwhitneyu(a, b, alternative='two-sided')
        except ValueError as e:
            results['message'] = f"Error: {e}"; stat, p_value = np.nan, np.nan
    
    results['stat'] = float(stat); results['p_value'] = float(p_value)
    return results

def format_test_results(results: dict) -> str:
    """Formatea los resultados del test en un string markdown legible."""
    if results.get('message'): return f"*{results['message']}*"
    if pd.isna(results['p_value']): return "*Error al calcular estad√≠sticas.*"
    
    p_value = results['p_value']
    p_display = f"p={p_value:.3g}" if p_value >= 0.001 else "p < 0.001"
    
    report_str = (
        f"**Test (sobre N por preparado):** {results['test_name']} (comparando {results['comparison_target']}). "
        f"**{results['stat_label']}={results['stat']:.2f}, {p_display}** "
        f"*(N(CTL)={results['n_a']}, N(Hip)={results['n_b']})*"
    )
    return report_str

def _download_df_button(df: pd.DataFrame, filename_base: str, label: str = "Descargar CSV"):
    """Crea un bot√≥n de descarga para un DataFrame."""
    csv = df.to_csv(index=False).encode("utf-8")
    st.download_button(label=label, data=csv, file_name=f"{filename_base}.csv", mime="text/csv")

def list_raw_images(raw_dir: Path) -> list[Path]:
    """Lista todas las im√°genes .tif/.tiff en los subdirectorios CTL y hip."""
    files = []
    for sub in ["CTL", "hip"]:
        d = raw_dir / sub
        if not d.exists(): continue
        for ext in ("*.tif", "*.tiff", "*.TIF", "*.TIFF"):
            files.extend(sorted(d.rglob(ext)))
    return files

def detect_group_from_path(p: Path) -> str:
    """Detecta el grupo (CTL o Hipoxia) desde la ruta del archivo."""
    return 'Hipoxia' if '/hip/' in str(p).replace('\\', '/').lower() else 'CTL'

# --- Carga de Datos (REFACTORIZADA) ---
@st.cache_data(ttl=60) # Cachear por 1 min (reducido para reflejar cambios m√°s r√°pido)
def load_all_metrics(raw_dir: Path, proc_dir: Path):
    """
    Carga y fusiona todas las m√©tricas (n√∫cleo, esqueleto, sholl) de todos 
    los preparados procesados.
    """
    files = list_raw_images(raw_dir)
    rows_skel = []
    rows_sholl = []
    rows_nuc = []
    rows_sholl_raw = [] # New list for raw profiles
    
    for p in files:
        od = proc_dir / p.stem
        group = detect_group_from_path(p)
        
        # 1. Cargar m√©tricas topol√≥gicas de esqueleto (skeletons/summary.csv)
        ps = od / "skeletons" / "summary.csv"
        if ps.exists():
            try:
                df = pd.read_csv(ps); df['prepared'] = f"{group}-{p.stem}"; df['group'] = group
                rows_skel.append(df)
            except Exception: pass
        
        # 2. Cargar m√©tricas de Sholl 2D (sholl_summary.csv)
        pss = od / "sholl_summary.csv"
        if pss.exists():
            try:
                df = pd.read_csv(pss); df['prepared'] = f"{group}-{p.stem}"; df['group'] = group
                rows_sholl.append(df)
            except Exception: pass

        # 2b. Cargar Perfiles Raw de Sholl (sholl_2d_native.csv)
        pr = od / "sholl_2d_native.csv"
        if pr.exists():
            try:
                # Cargar solo columnas necesarias para ahorrar memoria
                df = pd.read_csv(pr, usecols=['label', 'radius_um', 'intersections']) 
                df['prepared'] = f"{group}-{p.stem}"
                df['group'] = group
                rows_sholl_raw.append(df)
            except Exception: pass
            
        # 3. Cargar m√©tricas de n√∫cleo (03_nucleus_metrics.csv)
        pn = od / "03_nucleus_metrics.csv"
        if pn.exists():
            try:
                df = pd.read_csv(pn); df['prepared'] = f"{group}-{p.stem}"; df['group'] = group
                rows_nuc.append(df)
            except Exception: pass

    if not rows_skel and not rows_sholl and not rows_nuc and not rows_sholl_raw:
        return None, None, None

    # --- Fusi√≥n y Agregaci√≥n ---
    df_skel_all = pd.concat(rows_skel, ignore_index=True) if rows_skel else pd.DataFrame()
    df_nuc_all = pd.concat(rows_nuc, ignore_index=True) if rows_nuc else pd.DataFrame()
    df_sholl_all = pd.concat(rows_sholl, ignore_index=True) if rows_sholl else pd.DataFrame()
    
    # Estrategia de fusi√≥n: empezar con el DataFrame que tenga m√°s datos
    # y hacer left joins para preservar todas las filas
    
    if not df_skel_all.empty:
        # Comenzar con skeleton (m√°s completo)
        df_por_celula = df_skel_all.copy()
        
        # Agregar Sholl
        if not df_sholl_all.empty:
            df_por_celula = pd.merge(df_por_celula, df_sholl_all, 
                                     on=['label', 'prepared', 'group'], how='left')
    elif not df_sholl_all.empty:
        # Si no hay skeleton pero s√≠ Sholl, comenzar con Sholl
        df_por_celula = df_sholl_all.copy()
    else:
        # Si no hay ni skeleton ni Sholl, usar DataFrame vac√≠o
        df_por_celula = pd.DataFrame()
    
    # Agregar m√©tricas de n√∫cleo
    if not df_nuc_all.empty:
        # Filtrar solo candidatos a astrocitos
        df_nuc_astros = df_nuc_all[df_nuc_all['is_astrocyte_candidate'] == True].copy()
        
        if not df_nuc_astros.empty and 'label' in df_nuc_astros.columns:
            df_nuc_astros['label'] = df_nuc_astros['label'].astype(int)
            
            if not df_por_celula.empty and 'label' in df_por_celula.columns:
                # Merge con datos existentes
                df_por_celula = pd.merge(df_por_celula, df_nuc_astros, 
                                        on=['label', 'prepared', 'group'], how='left')
            elif df_por_celula.empty:
                # Si no hay skeleton ni sholl, al menos usar n√∫cleos
                df_por_celula = df_nuc_astros
        
    if df_por_celula.empty:
        return None, None

    # --- ¬°CR√çTICO! Soluci√≥n a Pseudoreplicaci√≥n ---
    # 1. DataFrame para gr√°ficos (todas las c√©lulas)
    df_plot = df_por_celula.copy()
    
    # 2. DataFrame para estad√≠stica (mediana por preparado)
    cols_to_agg = [
        # M√©tricas de Sholl
        'critical_radius_um', 'peak_intersections', 'auc',
        # M√©tricas nucleares
        'nucleus_volume_um3', 'nucleus_sphericity',
        # M√©tricas topol√≥gicas b√°sicas
        'n_branches', 'total_branch_length_um', 'mean_branch_length_um',
        'n_endpoints', 'n_junctions',
        # M√©tricas de tortuosidad
        'tortuosity_mean', 'tortuosity_max', 'tortuosity_std',
        # √çndices de complejidad
        'ramification_index', 'termination_index',
        # Distribuci√≥n de longitudes
        'branch_length_median_um', 'branch_length_p25_um', 'branch_length_p75_um',
        'branch_length_std_um', 'branch_length_cv',
        # Fragmentaci√≥n
        'n_connected_components'
    ]
    valid_cols_to_agg = [col for col in cols_to_agg if col in df_plot.columns]
    
    if not valid_cols_to_agg or 'prepared' not in df_plot.columns or 'group' not in df_plot.columns:
        return df_plot, pd.DataFrame(), pd.DataFrame() # No hay suficientes datos

    df_stats = df_plot.groupby(['prepared', 'group'])[valid_cols_to_agg].median().reset_index()
    
    # --- Fusi√≥n de Curvas Sholl (Raw) ---
    # Necesitamos cargar los perfiles raw para la gr√°fica de curvas
    df_sholl_curves = pd.DataFrame()
    if rows_sholl_raw:
        df_sholl_curves = pd.concat(rows_sholl_raw, ignore_index=True)
    
    return df_plot, df_stats, df_sholl_curves

# --- Cargar Datos ---
df_plot, df_stats, df_sholl_curves = load_all_metrics(RAW_DIR, PROC_DIR)

if df_plot is None or df_stats is None:
    st.error("No se encontraron m√©tricas procesadas (summary.csv, sholl_summary.csv, etc.) en `data/processed`.")
    st.stop()

# --- Estado del Pipeline ---
st.markdown("### üìä Estado del Procesamiento")
total_preps = df_stats['prepared'].nunique()

col_status1, col_status2, col_status3 = st.columns(3)

n_ctl = (df_stats['group'] == 'CTL').sum()
n_hip = (df_stats['group'] == 'Hipoxia').sum()

col_status1.metric("Total Preparados", total_preps)
col_status2.metric("CTL", n_ctl)
col_status3.metric("Hipoxia", n_hip)

# Verificar completitud de datos por tipo
numeric_cols_check = [col for col in df_stats.columns 
                      if col not in ['prepared', 'group'] and df_stats[col].dtype in ['float64', 'int64']]

# Sholl
sholl_cols = [c for c in numeric_cols_check if 'auc' in c or 'critical_radius' in c or 'peak' in c]
if sholl_cols:
    n_with_sholl = df_stats[sholl_cols[0]].notna().sum()
    pct_sholl = (n_with_sholl / total_preps) * 100
    col_status1.metric("Con datos Sholl", f"{n_with_sholl} ({pct_sholl:.0f}%)")

# Topolog√≠a
topo_cols = [c for c in numeric_cols_check if 'branch' in c or 'tortuosity' in c]
if topo_cols:
    n_with_topo = df_stats[topo_cols[0]].notna().sum()
    pct_topo = (n_with_topo / total_preps) * 100
    col_status2.metric("Con datos topol√≥gicos", f"{n_with_topo} ({pct_topo:.0f}%)")

# N√∫cleo
nuc_cols = [c for c in numeric_cols_check if 'nucleus' in c]
if nuc_cols:
    n_with_nuc = df_stats[nuc_cols[0]].notna().sum()
    pct_nuc = (n_with_nuc / total_preps) * 100
    col_status3.metric("Con datos nucleares", f"{n_with_nuc} ({pct_nuc:.0f}%)")

# Bot√≥n para refrescar datos
if st.button("üîÑ Refrescar datos (limpiar cach√©)", help="√ötil despu√©s de re-ejecutar el pipeline"):
    st.cache_data.clear()
    st.rerun()

st.markdown("---")

# --- Definir m√©tricas disponibles para comparar ---
METRIC_OPTIONS = {
    # Sholl
    'critical_radius_um': ("Sholl: Radio Cr√≠tico", "¬µm"),
    # Topolog√≠a
    'total_branch_length_um': ("Longitud Total Esqueleto", "¬µm"),
    'ramification_index': ("√çndice de Ramificaci√≥n (ramas/junctions)", "ratio"),
    'n_endpoints': ("N√∫mero de Terminaciones", "count"),
}

# Filtrar opciones basadas en las columnas que realmente existen
available_metrics = {k: v for k, v in METRIC_OPTIONS.items() if k in df_plot.columns}

st.markdown("### Comparaci√≥n Global de M√©tricas")
selected_metric = st.selectbox(
    "Seleccion√° la m√©trica a comparar:",
    options=available_metrics.keys(),
    format_func=lambda k: f"{available_metrics[k][0]} ({available_metrics[k][1]})" if available_metrics[k][1] else available_metrics[k][0]
)

metric_label = f"{available_metrics[selected_metric][0]} ({available_metrics[selected_metric][1]})" if available_metrics[selected_metric][1] else available_metrics[selected_metric][0]

st.markdown(f"#### {metric_label}")

# --- Informaci√≥n de Disponibilidad de Datos ---
if selected_metric in df_stats.columns:
    n_ctl = df_stats.loc[df_stats['group']=='CTL', selected_metric].dropna().shape[0]
    n_hip = df_stats.loc[df_stats['group']=='Hipoxia', selected_metric].dropna().shape[0]
    total_preps = n_ctl + n_hip
    
    col_info1, col_info2, col_info3 = st.columns(3)
    col_info1.metric("üìä Preparados con datos", total_preps)
    col_info2.metric("CTL", n_ctl)
    col_info3.metric("Hipoxia", n_hip)
    
    if total_preps < 6:
        st.warning(f"‚ö†Ô∏è Pocos datos disponibles para esta m√©trica. Se recomienda re-ejecutar el paso 04 (Sholl) o 05 (topolog√≠a) en m√°s preparados.")

# --- 1. Gr√°fico de Distribuci√≥n (usando df_plot) ---
st.markdown("**Distribuci√≥n por C√©lula (para visualizaci√≥n)**")
chart = boxplot_with_ticks(df_plot.dropna(subset=[selected_metric]), selected_metric, 'group', title_x=metric_label)
st.altair_chart(chart, use_container_width=True)

# --- 2. Test Estad√≠stico (usando df_stats) ---
st.markdown("**Test Estad√≠stico (sobre medianas por preparado)**")
if selected_metric not in df_stats.columns:
    st.warning(f"La m√©trica '{selected_metric}' no se pudo agregar por preparado.")
else:
    try:
        a = df_stats.loc[df_stats['group']=='CTL', selected_metric].dropna().to_numpy()
        b = df_stats.loc[df_stats['group']=='Hipoxia', selected_metric].dropna().to_numpy()
        
        if a.size > 0 and b.size > 0:
            test_results = run_comparison_test(a, b)
            
            # Verificar si hay datos suficientes
            if test_results.get('message'):
                # Datos insuficientes o problema
                st.warning(test_results['message'])
                col_test1, col_test2, col_test3, col_test4 = st.columns(4)
                col_test1.metric("Test Usado", "‚Äî")
                col_test2.metric("Estad√≠stico", "nan")
                col_test3.metric("P-valor", "p = nan ns")
                col_test4.metric("Significancia", "‚ö™")
            elif pd.isna(test_results['p_value']):
                # Error en c√°lculo
                st.error("No se pudo calcular el test estad√≠stico.")
                col_test1, col_test2, col_test3, col_test4 = st.columns(4)
                col_test1.metric("Test Usado", "‚Äî")
                col_test2.metric("Estad√≠stico", "nan")
                col_test3.metric("P-valor", "p = nan ns")
                col_test4.metric("Significancia", "‚ö™")
            else:
                # Test exitoso
                reporte_stats = format_test_results(test_results)
                
                # Mostrar estad√≠stica en formato profesional
                col_test1, col_test2, col_test3, col_test4 = st.columns(4)
                col_test1.metric("Test Usado", test_results['test_name'])
                col_test2.metric("Estad√≠stico", f"{test_results['stat_label']}={test_results['stat']:.3f}")
                
                # Color para p-valor
                p_val = test_results['p_value']
                if p_val < 0.001:
                    p_display = "p < 0.001"
                    sig_level = "***"
                    p_color = "üî¥"
                elif p_val < 0.01:
                    p_display = f"p = {p_val:.3f}"
                    sig_level = "**"
                    p_color = "üü†"
                elif p_val < 0.05:
                    p_display = f"p = {p_val:.3f}"
                    sig_level = "*"
                    p_color = "üü°"
                else:
                    p_display = f"p = {p_val:.3f}"
                    sig_level = "ns"
                    p_color = "‚ö™"
                
                col_test3.metric("P-valor", f"{p_display} {sig_level}")
                col_test4.metric("Significancia", p_color)
                
                st.markdown(reporte_stats)
        else:
            st.caption("No hay suficientes datos por preparado para ambos grupos para el test.")
    except Exception as e:
        st.caption(f"Error al calcular estad√≠sticas: {e}")
        st.exception(e)


st.markdown("---")
st.markdown("### üìà An√°lisis de Curvas de Sholl")

if df_sholl_curves.empty:
    st.info("No hay datos de curvas Sholl disponibles para comparar.")
else:
    # 1. Agregaci√≥n Robusta: Promedio por preparado primero (evita pseudoreplicaci√≥n)
    # Unidad experimental = Preparado
    df_sholl_prep = df_sholl_curves.groupby(['group', 'prepared', 'radius_um'])['intersections'].mean().reset_index()
    
    # 2. Visualizaci√≥n (Media ¬± SEM de los preparados)
    st.markdown("**Perfiles de Sholl (Media ¬± Error Est√°ndar de los Preparados)**")
    
    base = alt.Chart(df_sholl_prep).encode(
        x=alt.X('radius_um:Q', title='Radio (¬µm)'),
        color=alt.Color('group:N', scale=alt.Scale(domain=['CTL', 'Hipoxia'], range=['#377eb8', '#e41a1c']))
    )
    
    line = base.mark_line(point=False).encode(
        y=alt.Y('mean(intersections):Q', title='Intersecciones (Media)')
    )
    
    band = base.mark_errorband(extent='stderr').encode(
        y=alt.Y('intersections:Q', title='Intersecciones')
    )
    
    chart_sholl = (band + line).properties(height=400)
    st.altair_chart(chart_sholl, use_container_width=True)
    
    # 3. Estad√≠stica (Mixed ANOVA)
    st.markdown("**An√°lisis Estad√≠stico (ANOVA Mixto)**")
    st.caption("Factor Entre-Sujetos: Grupo | Factor Intra-Sujetos: Radio | Sujeto: Preparado")
    
    try:
        # Verificar requisitos de datos para ANOVA
        # Necesitamos que todos los sujetos tengan datos en los mismos radios (balanceado idealmente)
        # O al menos suficientes datos. Pingouin maneja datos desbalanceados, pero hay l√≠mites.
        
        n_groups = df_sholl_prep['group'].nunique()
        n_preps = df_sholl_prep['prepared'].nunique()
        
        if n_groups < 2 or n_preps < 4:
            st.warning("‚ö†Ô∏è Insuficientes datos para calcular ANOVA (se requieren al menos 2 grupos y m√∫ltiples preparados).")
        else:
            with st.spinner("Calculando ANOVA Mixto..."):
                # Ejecutar ANOVA Mixto
                aov = pg.mixed_anova(
                    data=df_sholl_prep, 
                    dv='intersections', 
                    within='radius_um', 
                    between='group', 
                    subject='prepared'
                )
                
                # Formatear tabla para mostrar
                st.dataframe(
                    aov.round(4),
                    use_container_width=True,
                    column_config={
                        "Source": "Fuente de Variaci√≥n",
                        "SS": "Suma Cuadrados",
                        "DF1": "GL1",
                        "DF2": "GL2",
                        "MS": "Cuad. Medio",
                        "F": "F",
                        "p-unc": "P-valor",
                        "np2": "Eta¬≤ parcial"
                    }
                )
                
                # Interpretaci√≥n autom√°tica
                p_interaction = aov.loc[aov['Source'] == 'Interaction', 'p-unc'].values[0]
                p_group = aov.loc[aov['Source'] == 'group', 'p-unc'].values[0]
                
                res_str = ""
                if p_interaction < 0.05:
                    res_str += f"üî¥ **Interacci√≥n Significativa (p={p_interaction:.3f}):** El perfil de ramificaci√≥n difiere significativamente entre grupos a lo largo del radio."
                else:
                    res_str += f"‚ö™ **Interacci√≥n No Significativa (p={p_interaction:.3f}):** Los perfiles tienen formas similares."
                    
                if p_group < 0.05:
                    res_str += f" | üü† **Efecto de Grupo Significativo (p={p_group:.3f}):** Existe una diferencia global en la complejidad."
                
                st.info(res_str)
                
                with st.expander("üìñ ¬øC√≥mo leer esta tabla?"):
                    st.markdown("""
                    **Fuentes de Variaci√≥n (Source):**
                    *   **group**: ¬øHay diferencias totales entre CTL y Hipoxia? (e.g. uno tiene m√°s ramas en general).
                    *   **radius_um**: Efecto de la distancia (siempre significativo en Sholl).
                    *   **Interaction**: ¬øCambia la *forma* de la curva? (CR√çTICO: Si es significativo, los grupos tienen arquitecturas diferentes, no solo m√°s/menos ramas).
                    
                    **Indicadores:**
                    *   **P-valor**: Probabilidad de error. Si es < 0.05, el efecto es real.
                    *   **Eta¬≤ parcial**: Tama√±o del efecto (0.01=peque√±o, 0.06=medio, 0.14=grande). Indica qu√© % de la varianza explica ese factor.
                    """)
                
    except Exception as e:
        st.error(f"No se pudo calcular ANOVA: {e}")
        st.caption("Verific√° que los radios sean consistentes entre preparados.")

st.markdown("---")
st.markdown("### üìä Datos Agregados y Exportaci√≥n")

st.markdown("""
Los datos se presentan en dos formatos:
- **Por C√©lula**: Todas las c√©lulas individuales (√∫til para gr√°ficos de distribuci√≥n)
- **Por Preparado**: Mediana de cada preparado (correcto para an√°lisis estad√≠stico, evita pseudoreplicaci√≥n)
""")

col1, col2 = st.columns(2)
with col1:
    st.markdown("**Datos por C√©lula (para gr√°ficos)**")
    st.caption(f"Total: {df_plot.shape[0]} c√©lulas de {df_plot['prepared'].nunique()} preparados")
    st.dataframe(
        df_plot.round(3),
        use_container_width=True,
        height=400,
        column_config={
            "label": st.column_config.NumberColumn("ID", format="%d"),
            "group": st.column_config.TextColumn("Grupo"),
            "prepared": st.column_config.TextColumn("Preparado")
        }
    )
    _download_df_button(df_plot, "metricas_por_celula", "‚¨áÔ∏è Descargar CSV (por c√©lula)")
    
with col2:
    st.markdown("**Datos por Preparado (para estad√≠stica)**")
    st.caption(f"Total: {df_stats.shape[0]} preparados (mediana de cada preparado)")
    st.dataframe(
        df_stats.round(3),
        use_container_width=True,
        height=400,
        column_config={
            "group": st.column_config.TextColumn("Grupo"),
            "prepared": st.column_config.TextColumn("Preparado")
        }
    )
    _download_df_button(df_stats, "metricas_por_preparado", "‚¨áÔ∏è Descargar CSV (por preparado)")
